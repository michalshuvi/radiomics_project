{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train Segmentation model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KpT1hKl5xaDH","executionInfo":{"status":"ok","timestamp":1602849420290,"user_tz":-180,"elapsed":2130,"user":{"displayName":"Michal Shuvi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggq1z_Ac_QIyxaoPGF9c_xgQAZ9wcDrIYof8ubY2kE=s64","userId":"09312255182311287472"}},"outputId":"6231df20-bb7e-4cb2-8cd1-f392c67a5a96","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import sys, os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","sys.path.append('/content/drive/My Drive/Radiomics Workshop')\n","os.chdir('drive/My Drive/Radiomics Workshop')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bYlIOckkhVQL"},"source":["from mice_dataset import PatchMiceDatasetFromTensor\n","from torch.utils.data import DataLoader\n","\n","bs = 10\n","\n","dataset_name = 'dataForNet_shuffle_by_slices_2d_600_30per'\n","\n","train_dataset = PatchMiceDatasetFromTensor(f'datasets/{dataset_name}') #, max_dataset_size=10)\n","test_dataset = PatchMiceDatasetFromTensor(f'datasets/{dataset_name}', is_train=False)\n","\n","dl_train = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n","dl_test = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n","\n","print(len(dl_train), len(dl_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_0_Xh8El_00"},"source":["import numpy as np\n","import tqdm\n","import torch\n","import itertools\n","from network import UNet\n","from network import dice_loss\n","import utils\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(device)\n","\n","model_name = 'best'\n","root_path = 'results/models/segmentation'\n","model_path = f'{root_path}/{model_name}'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0wgKBcncvxak"},"source":["\n","use_location = False\n","location = None\n","save = True\n","num_epochs = 100\n","train_params =   {\n","    'device': device,\n","    'n_channels': 1,\n","    'n_classes': 1,\n","    'criterion': dice_loss,\n","    'optimizer': torch.optim.Adam,\n","    'lr': 0.0002,\n","    'layers': [16, 32, 64, 128],\n","    \"scheduler_params\" : {\n","                    \"total_epochs_num\": num_epochs,\n","                    \"static_epochs_num\": num_epochs / 5\n","                    },\n","}\n","\n","model = UNet(**train_params).to(device)\n","utils.init_model_weights(model)\n","print(model)\n","\n","train_loss_per_epoch, test_loss_per_epoch, accuracy_per_epoch = [], [], []\n","min_iou_epoch = 0\n","min_test_loss_epoch = float(\"inf\")\n","\n","for epoch in range(num_epochs):\n","  train_loss_per_batch, test_loss_per_batch = [], []\n","  iou_per_epoch = 0\n","  print(f'--- EPOCH {epoch + 1}/{num_epochs} ---')\n","\n","  #Train\n","  with tqdm.tqdm(total=len(dl_train), file=sys.stdout) as pbar:\n","    for batch in dl_train:\n","      image = batch['image'].to(device, dtype=torch.float32)\n","      mask = batch['mask'].to(device, dtype=torch.float32)\n","      loss = model.train_batch(image, mask)\n","      train_loss_per_batch.append(loss.item())\n","      pbar.update()\n","    train_loss_per_epoch.append(np.mean(train_loss_per_batch))\n","    model.update_learning_rate()\n","  \n","  #Test\n","  with tqdm.tqdm(total=len(dl_test), file=sys.stdout) as pbar:\n","    for batch in dl_test:\n","      image = batch['image'].to(device, dtype=torch.float32)\n","      mask = batch['mask'].to(device, dtype=torch.float32)\n","      cross_entropy_loss, cur_mistakes_num = model.test_batch(image, mask)\n","      iou_per_epoch += cur_mistakes_num\n","      test_loss_per_batch.append(cross_entropy_loss)\n","      pbar.update()\n","\n","  cur_epoch_test_loss = np.mean(test_loss_per_batch)\n","  test_loss_per_epoch.append(cur_epoch_test_loss)\n","  \n","  print(\"Epoch\", epoch)\n","  print(\"Train loss\", train_loss_per_epoch[-1])\n","  print(\"Test loss\", test_loss_per_epoch[-1])\n","  total_iou = iou_per_epoch / (len(dl_test))\n","  accuracy_per_epoch.append(total_iou)\n","  print(\"Test Acurracy\", total_iou)\n","  if cur_epoch_test_loss < min_test_loss_epoch:\n","    min_test_loss_epoch = cur_epoch_test_loss\n","\n","    if save:\n","      if not os.path.exists(model_path):\n","        os.makedirs(model_path, exist_ok=True)\n","      print(f'**** Saving in epoch {epoch + 1} *****')\n","      saved_state = dict(test_losses=test_loss_per_epoch,\n","                          train_losses=train_loss_per_epoch,\n","                          test_accuracies=accuracy_per_epoch,\n","                          model_state=model.state_dict(),\n","                          dataset_name=dataset_name,\n","                          train_params=train_params\n","                        )\n","      torch.save(saved_state, f\"{model_path}/model_{epoch + 1}_epochs\")\n","      best_state_dict = model.state_dict()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KeIaHVeykdk_"},"source":["# Load Model\n","load best model and print patches"]},{"cell_type":"code","metadata":{"id":"NrhmDWdETPOS"},"source":["from utils import tensors_as_images\n","\n","epoch_name = \"model_67_epochs\"\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","params = torch.load(f\"{model_path}/{epoch_name}\", map_location=device)\n","train_params = params['train_params']\n","model_state = params['model_state']\n","model = UNet(**train_params).to(device)\n","model.load_state_dict(model_state)\n","model.to(device)\n","\n","# model.load_state_dict(best_state_dict)\n","count = 0\n","\n","\n","for i, batch in enumerate(dl_test):\n","  image = batch['image'].to(device)\n","  mask = batch['mask'].to(device)\n","  if batch['label'][0] == 0:\n","    continue\n","  count += 1\n","  cross_entropy_loss, cur_mistakes_num = model.test_batch(image, mask)\n","  with torch.no_grad():\n","    output = model(image).cpu()\n","    # output_mask = torch.where(output[0] > 0.5, torch.ones(output[0].size()), torch.zeros(output[0].size()))\n","    # output = torch.sigmoid(output)\n","    tensors_as_images([image[0].cpu(), mask[0].cpu(), output[0]])\n","  if count == 50:\n","    break"],"execution_count":null,"outputs":[]}]}