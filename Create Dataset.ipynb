{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"createdataset.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1UCkF04DR4CQ0f7teYySNvc8u_PKLQ_Jb","authorship_tag":"ABX9TyPEE/N9/3ls8SkyOFt4YbGK"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KpT1hKl5xaDH"},"source":["import sys, os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","sys.path.append('/content/drive/My Drive/radiomics/Radiomics Workshop')\n","os.chdir('drive/My Drive/radiomics/Radiomics Workshop')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZkNVsNDzSCT"},"source":["!pip install SimpleITK==1.2.4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2WoHlYZzdXY"},"source":["!pip install pyradiomics===3.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qW4hsfcZ3z9i"},"source":["import torch\n","import random\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","\n","MICE_IDS = [\"MB1333220714F000H00000000C000000\", \"MB1396110913F000H00000000C000000\", \"MB1312240614F000H00000000C000000\",\n","            \"MB1444220714F000H00000000C000000\", \"MB1589241214FC00H00004052C000000\", \"MB1752210615FC00H00000557C000000\",\n","            \"MB1858100815FC00H00001912C000000\", \"MB1858230615FC00H00001912C000000\",\n","            \"MB1583050215FC00H00004052C000000\", \"MB1598010315FC00H00004457C000000\", \"MB1695040215F000H00000000C000000\",\n","            \"MB1392140814F000H00000000C000000\", \"MB1588050215FC00H00004052C000000\", \"MB4134091016F000H00000000C000000\",\n","            \"MB1472110315FC00H00004052C000000\", \"MB1755210615FC00H00000557C000000\", \"MB1953010315FC00H00004457C000000\",\n","            \"MB1398110913F000H00000000C000000\", \"MB1468010315FC00H00003912C000000\",\n","            \"MB1363150215F000H00000000C000000\", \"MB1370270414F000H00000000C000000\", \"MB1408220714F000H00000000C000000\",\n","             \"MB1452010315FC00H00000188C000000\", \"MB1512290714F000H00000000C000000\", \"MB1513090614F000H00000000C000000\",\n","             \"MB1539110315FC00H00001912C000000\", \"MB1747010315FC00H00000072C000000\", \"MB1858140715FC00H00001912C000000\",\n","             \"MB4022091016F000H00000000C000000\"]\n","\n","'''\n","rearrange takes dataset located in old_folder_path, and copy and split it into train and test in new_folder_path.\n","tumor_threshold - half of the patches in both train and test will have at least this amount of tumor, and the other half less than that.\n","train_precentage - the percentage of the train compared to all data (train+test)\n","mice - The names of the folders in the old_folder_path, each contains different mice scan, that we want to split into train and test.\n","The default if all the mice above, but one can pass other scans, for example: rearrange(mice=[\"MB1452010315FC00H00000188C000000\", \"MB1513090614F000H00000000C000000\"])\n","by_slices - if we want to split between train and test randomly - by_slices=False; if we want to split them between different range of slices, by_slices=True\n","'''\n","\n","def rearrange(old_folder_path, new_folder_path, tumor_threshold, train_precentage, mice=MICE_IDS, by_slices=False):\n","  for mouse in mice:\n","    print(\"start\", mouse)\n","    current_folder = old_folder_path + \"/\" + mouse\n","    img_names = [f for f in listdir(current_folder) if isfile(join(current_folder, f))]\n","    all_tumor_tensors = []\n","    all_no_tumor_tensors = []\n","    print(\"loading\")\n","    for i in range(len(img_names)):\n","      loaded = torch.load(current_folder+\"/\"+img_names[i])\n","      if loaded[\"tumor_percentage\"] >= tumor_threshold:\n","        all_tumor_tensors.append(loaded)\n","      else:\n","        all_no_tumor_tensors.append(loaded)\n","    if by_slices:\n","      all_tumor_tensors = sorted(all_tumor_tensors, key=lambda k: k['slice_range'][0])\n","      print(0, all_tumor_tensors[0]['slice_range'])\n","      print(int(len(all_tumor_tensors)/2), all_tumor_tensors[int(len(all_tumor_tensors)/2)]['slice_range'])\n","      print(len(all_tumor_tensors)-1, all_tumor_tensors[len(all_tumor_tensors)-1]['slice_range'])\n","      all_no_tumor_tensors = sorted(all_no_tumor_tensors, key=lambda k: k['slice_range'][0])\n","    else:\n","      random.shuffle(all_tumor_tensors)\n","      random.shuffle(all_no_tumor_tensors)\n","    \n","    train_size_tumor = int(train_precentage*len(all_tumor_tensors))\n","    train_size_no_tumor = int(train_precentage*len(all_no_tumor_tensors))\n","\n","    print(\"saving\")  \n","    resave(all_tumor_tensors, 0, train_size_tumor, \n","           folder = new_folder_path + \"/train/\" + mouse, file_prefix=\"more\")\n","    resave(all_tumor_tensors, train_size_tumor+1, len(all_tumor_tensors), \n","           folder = new_folder_path + \"/test/\" + mouse, file_prefix=\"more\") \n","    resave(all_no_tumor_tensors, 0, train_size_no_tumor, \n","           folder = new_folder_path + \"/train/\" + mouse, file_prefix=\"less\")\n","    resave(all_no_tumor_tensors, train_size_no_tumor+1, len(all_no_tumor_tensors), \n","           folder = new_folder_path + \"/test/\" + mouse, file_prefix=\"less\")   \n","    print(\"finish\", mouse)\n","    \n","    \n","def resave(dict_arr, start_index, end_index, folder, file_prefix):\n","  if not os.path.isdir(folder):\n","    os.makedirs(folder)\n","  counter = 1\n","  for i in range(start_index, end_index):\n","    torch.save(dict_arr[i], folder + \"/\" + file_prefix + \"_\" + str(counter))\n","    counter += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Zp2loz91S76"},"source":["2d dataset creation"]},{"cell_type":"code","metadata":{"id":"UyFVncLiNjBa"},"source":["from create_data_set import main\n","\n","'''\n","for full information about the main function's arguments, see the notes above the create_dataset function, in create_data_set.py. If you have new scans,\n","that you want to run the process just on them, make sure to create a list that contains only the scans' names\n","(for example arr= [\"MB1755210615FC00H00000557C000000\", \"MB1333220714F000H00000000C000000\"]) and pass this array as an argument to both main and\n","rearrange functions. The arguments for \"rearrange\" listed above.\n","Make sure you use the right parameters for you.\n","'''\n","\n","old_folder_path = \"datasets/dataForNet_shuffle_by_slices_2d_600_30per\"\n","new_folder_path = \"datasets/dataForNet_shuffle_by_slices_2d_600_30per\"\n","tumor_threshold= 0.3\n","train_precentage = 0.65\n","\n","main(inp_path=\"datasets/miceData\", data_per_mouse=600, patch_size=50, s_per_patch=1, tumor_percent=0.3,\n","     folder_name=old_folder_path, to_shuffle=True, is_data_edited=False, to_resize=True)\n","\n","'''\n","One can also use already converted png (from DICOM) files, but for you it will be probably easier to use the above option.\n","Here is an example regardless:\n","main(inp_path=\"datasets/newMiceData\", data_per_mouse=600, patch_size=50, s_per_patch=1, tumor_percent=0.3,\n","     folder_name=old_folder_path, to_shuffle=True, is_data_edited=True)\n","'''\n","\n","rearrange(old_folder_path=old_folder_path, new_folder_path=new_folder_path,\n","          tumor_threshold=tumor_threshold, train_precentage=train_precentage, by_slices=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nCNo1U1c1WgQ"},"source":["3d dataset creation"]},{"cell_type":"code","metadata":{"id":"CJHAnOczq1zB"},"source":["from create_data_set import main\n","\n","'''\n","for full information about the main function's arguments, see the notes above the create_dataset function, in create_data_set.py. If you have new scans,\n","that you want to run the process just on them, make sure to create a list that contains only the scans' names\n","(for example arr= [\"MB1755210615FC00H00000557C000000\", \"MB1333220714F000H00000000C000000\"]) and pass this array as an argument to both main and\n","rearrange functions. The arguments for \"rearrange\" listed above.\n","Make sure you use the right parameters for you.\n","'''\n","\n","old_folder_path = \"datasets/‏‏dataForNet_new_3d_300_20per\"\n","new_folder_path = \"datasets/‏‏dataForNet_new_3d_300_20per\"\n","tumor_threshold= 0.2\n","train_precentage = 0.65\n","\n","main(inp_path=\"datasets/miceData\", data_per_mouse=300, patch_size=30, s_per_patch=30, tumor_percent=0.2,\n","     folder_name=old_folder_path, to_shuffle=True, is_data_edited=False, to_resize=True)\n","\n","\n","'''\n","One can also use already converted png (from DICOM) files, but for you it will be probably easier to use the above option.\n","Here is an example regardless:\n","main(inp_path=\"datasets/newMiceData\", data_per_mouse=300, patch_size=30, s_per_patch=30, tumor_percent=0.2,\n","     folder_name=old_folder_path, to_shuffle=True, is_data_edited=True)\n","'''\n","\n","rearrange(old_folder_path=old_folder_path, new_folder_path=new_folder_path,\n","          tumor_threshold=tumor_threshold, train_precentage=train_precentage, by_slices=False)"],"execution_count":null,"outputs":[]}]}