{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train 3D Classifier model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KpT1hKl5xaDH"},"source":["import sys, os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","sys.path.append('/content/drive/My Drive/Radiomics Workshop')\n","os.chdir('drive/My Drive/Radiomics Workshop')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bYlIOckkhVQL"},"source":["from mice_dataset import PatchMiceDatasetFromTensor\n","from torch.utils.data import DataLoader\n","\n","bs = 10\n","\n","dataset_name = '‏‏dataForNet_new_3d_300_20per'\n","\n","# tumor threshold can be changed here and you can add max_dataset_size\n","train_dataset = PatchMiceDatasetFromTensor(f'datasets/{dataset_name}', tumor_threshold=0.2, is_3d=True)  \n","test_dataset = PatchMiceDatasetFromTensor(f'datasets/{dataset_name}', tumor_threshold=0.2, is_3d=True, is_train=False)\n","\n","dl_train = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n","dl_test = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n","\n","print(len(dl_train), len(dl_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0wgKBcncvxak"},"source":["import numpy as np\n","import tqdm\n","import torch\n","from network import Classifier3D\n","import utils\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(device)\n","\n","\n","save = True\n","num_epochs = 50\n","model_name = 'classification_3d_new_net'\n","root_path = 'results/models/classification'\n","model_path = f'{root_path}/{model_name}'\n","\n","train_params =   {\n","    'in_channels': 1,\n","    'device': device,\n","    'lr': 0.0002,\n","    'scheduler_params' : {\n","                'total_epochs_num': num_epochs,\n","                'static_epochs_num': num_epochs / 5\n","                },\n","}\n","\n","model = Classifier3D(**train_params).to(device)\n","utils.init_model_weights(model)\n","print(model)\n","\n","\n","train_loss_per_epoch, accuracy_per_epoch, test_loss_per_epoch= [],  [], []\n","min_mistake_num_epoch = float(\"inf\")\n","\n","for epoch in range(num_epochs):\n","  train_loss_per_batch, test_loss_per_batch = [], []\n","  mistake_num_epoch = 0\n","  print(f'--- EPOCH {epoch + 1}/{num_epochs} ---')\n","\n","  #Train\n","  with tqdm.tqdm(total=len(dl_train), file=sys.stdout) as pbar:\n","    for batch in dl_train:\n","      image = batch['image'].to(device)\n","      label = batch['label'].to(device)\n","      loss = model.train_batch(image, label)\n","      train_loss_per_batch.append(loss.item())\n","      pbar.update()\n","    train_loss_per_epoch.append(np.mean(train_loss_per_batch))\n","    model.update_learning_rate()\n","  \n","  #Test\n","  with tqdm.tqdm(total=len(dl_test), file=sys.stdout) as pbar:\n","    for batch in dl_test:\n","      image = batch['image'].to(device)\n","      label = batch['label'].to(device)\n","      cross_entropy_loss, cur_mistakes_num = model.test_batch(image, label)\n","      mistake_num_epoch += cur_mistakes_num\n","      test_loss_per_batch.append(cross_entropy_loss.item())\n","      pbar.update()\n","\n","  test_loss_per_epoch.append(np.mean(test_loss_per_batch))\n","  \n","  print(\"Epoch\", epoch)\n","  print(\"Train loss\", train_loss_per_epoch[-1])\n","  print(\"Test loss\", test_loss_per_epoch[-1])\n","  mistake_rate = mistake_num_epoch / (len(test_dataset))\n","  accuracy_per_epoch.append(1 - mistake_rate)\n","  print(\"Test Acurracy\", 1 - mistake_rate)\n","  if mistake_num_epoch < min_mistake_num_epoch:\n","    min_mistake_num_epoch = mistake_num_epoch\n","    if save:\n","      if not os.path.exists(model_path):\n","        os.makedirs(model_path, exist_ok=True)\n","      print(f'**** Saving in epoch {epoch + 1} *****')\n","      saved_state = dict(test_losses=test_loss_per_epoch,\n","                          train_losses=train_loss_per_epoch,\n","                          test_accuracies=accuracy_per_epoch,\n","                          model_state=model.state_dict(),\n","                          dataset_name=dataset_name,\n","                          train_params=train_params\n","                        )\n","      torch.save(saved_state, f\"{model_path}/model_{epoch + 1}_epochs\")"],"execution_count":null,"outputs":[]}]}